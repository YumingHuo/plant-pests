                 from  n    params  module                                  arguments
  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]
  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]
  2                -1  1      4800  models.common.C3                        [32, 32, 1]
  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]
  4                -1  2     29184  models.common.C3                        [64, 64, 2]
  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  6                -1  3    156928  models.common.C3                        [128, 128, 3]
  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  8                -1  1    296448  models.common.C3                        [256, 256, 1]
  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]
 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]
 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]
 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]
 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]
 24      [17, 20, 23]  1     14883  models.yolo.Detect                      [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]
YOLOv5n_w2y summary: 214 layers, 1772035 parameters, 1772035 gradients, 4.2 GFLOPs
Transferred 342/349 items from weights\yolov5n.pt
[34m[1mAMP: [39m[22mchecks passed
[34m[1moptimizer:[39m[22m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias
[34m[1mtrain: [39m[22mScanning D:\CV_LEARN\å®žæˆ˜é¡¹ç›®6ï¼šYOLOv5å·¥åœ°é˜²æŠ¤æ£€æµ‹\windowsè½¯ä»¶\datasets\CHV_dataset\labels\train.cache... 1064 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1064/1064 [00:00<?, ?it/s]

[34m[1mval: [39m[22mScanning D:\CV_LEARN\å®žæˆ˜é¡¹ç›®6ï¼šYOLOv5å·¥åœ°é˜²æŠ¤æ£€æµ‹\windowsè½¯ä»¶\datasets\CHV_dataset\labels\val... 131 images, 0 backgrounds, 2 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133/133 [00:08<00:00, 14.93it/s]
[34m[1mval: [39m[22mWARNING  D:\CV_LEARN\6YOLOv5\windows\datasets\CHV_dataset\images\val\ppe_0332.jpg: ignoring corrupt image/label: [Errno 22] Invalid argument
[34m[1mval: [39m[22mWARNING  D:\CV_LEARN\6YOLOv5\windows\datasets\CHV_dataset\images\val\ppe_0335.jpg: ignoring corrupt image/label: [Errno 22] Invalid argument
[34m[1mval: [39m[22mNew cache created: D:\CV_LEARN\6YOLOv5\windows\datasets\CHV_dataset\labels\val.cache
[34m[1mAutoAnchor: [39m[22m4.75 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset
Plotting labels to yolo_test\base_n8\labels.jpg...
Image sizes 640 train, 640 val
Using 1 dataloader workers
Logging results to [1myolo_test\base_n8
Starting training for 120 epochs...
      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
  0%|          | 0/54 [00:00<?, ?it/s]
Traceback (most recent call last):
  File ".\train.py", line 640, in <module>
    main(opt)
  File ".\train.py", line 529, in main
    train(opt.hyp, opt, device, callbacks)
  File ".\train.py", line 284, in train
    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------
  File "D:\Miniconda3\envs\torch_gpu\lib\site-packages\tqdm\std.py", line 1178, in __iter__
    for obj in iterable:
  File "D:\CV_LEARN\å®žæˆ˜é¡¹ç›®6ï¼šYOLOv5å·¥åœ°é˜²æŠ¤æ£€æµ‹\windowsè½¯ä»¶\yolov5\utils\dataloaders.py", line 172, in __iter__
    yield next(self.iterator)
  File "D:\Miniconda3\envs\torch_gpu\lib\site-packages\torch\utils\data\dataloader.py", line 521, in __next__
    data = self._next_data()
  File "D:\Miniconda3\envs\torch_gpu\lib\site-packages\torch\utils\data\dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "D:\Miniconda3\envs\torch_gpu\lib\site-packages\torch\utils\data\dataloader.py", line 1229, in _process_data
    data.reraise()
  File "D:\Miniconda3\envs\torch_gpu\lib\site-packages\torch\_utils.py", line 425, in reraise
    raise self.exc_type(msg)
cv2.error: Caught error in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "D:\Miniconda3\envs\torch_gpu\lib\site-packages\torch\utils\data\_utils\worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "D:\Miniconda3\envs\torch_gpu\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "D:\Miniconda3\envs\torch_gpu\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "D:\CV_LEARN\å®žæˆ˜é¡¹ç›®6ï¼šYOLOv5å·¥åœ°é˜²æŠ¤æ£€æµ‹\windowsè½¯ä»¶\yolov5\utils\dataloaders.py", line 661, in __getitem__
    img, labels = self.load_mosaic(index)
  File "D:\CV_LEARN\å®žæˆ˜é¡¹ç›®6ï¼šYOLOv5å·¥åœ°é˜²æŠ¤æ£€æµ‹\windowsè½¯ä»¶\yolov5\utils\dataloaders.py", line 760, in load_mosaic
    img, _, (h, w) = self.load_image(index)
  File "D:\CV_LEARN\å®žæˆ˜é¡¹ç›®6ï¼šYOLOv5å·¥åœ°é˜²æŠ¤æ£€æµ‹\windowsè½¯ä»¶\yolov5\utils\dataloaders.py", line 735, in load_image
    im = cv2.imread(f)  # BGR
  File "D:\CV_LEARN\å®žæˆ˜é¡¹ç›®6ï¼šYOLOv5å·¥åœ°é˜²æŠ¤æ£€æµ‹\windowsè½¯ä»¶\yolov5\utils\general.py", line 1123, in imread
    return cv2.imdecode(np.fromfile(filename, np.uint8), flags)
cv2.error: OpenCV(4.7.0) D:\a\opencv-python\opencv-python\opencv\modules\core\src\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 33292800 bytes in function 'cv::OutOfMemoryError'